Sat Aug 24 13:09:34 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:0F:00.0 Off |                    0 |
| N/A   25C    P0             51W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+


Experiment Name: org_architecture
Experiment Details: None


Dataset Name: imagenet100
Seed: 64
Batch Size: 64
Number of Epochs: 100
Learning Rate: 3e-4
Input Channel: 3
Patch Size: 16
Embedding Size: 768
Input Image Size: 224
ViT Depth: 12
Number of Classes: 100
WandB Project: vit-small-data
WandB Run Name: org_architecture_imagenet100_Lr_3e-4_EMB_768_patch_16_depth_12
Output Directory: results


==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─PatchEmbedding: 1-1                    [-1, 197, 768]            --
|    └─Sequential: 2-1                   [-1, 196, 768]            --
|    |    └─Conv2d: 3-1                  [-1, 768, 14, 14]         590,592
|    |    └─Rearrange: 3-2               [-1, 196, 768]            --
├─TransformerEncoder: 1-2                [-1, 197, 768]            --
|    └─TransformerEncoderBlock: 2-2      [-1, 197, 768]            --
|    |    └─Residual: 3-3                [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-4                [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-3      [-1, 197, 768]            --
|    |    └─Residual: 3-5                [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-6                [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-4      [-1, 197, 768]            --
|    |    └─Residual: 3-7                [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-8                [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-5      [-1, 197, 768]            --
|    |    └─Residual: 3-9                [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-10               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-6      [-1, 197, 768]            --
|    |    └─Residual: 3-11               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-12               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-7      [-1, 197, 768]            --
|    |    └─Residual: 3-13               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-14               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-8      [-1, 197, 768]            --
|    |    └─Residual: 3-15               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-16               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-9      [-1, 197, 768]            --
|    |    └─Residual: 3-17               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-18               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-10     [-1, 197, 768]            --
|    |    └─Residual: 3-19               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-20               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-11     [-1, 197, 768]            --
|    |    └─Residual: 3-21               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-22               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-12     [-1, 197, 768]            --
|    |    └─Residual: 3-23               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-24               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-13     [-1, 197, 768]            --
|    |    └─Residual: 3-25               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-26               [-1, 197, 768]            4,723,968
├─ClassificationHead: 1-3                [-1, 100]                 --
|    └─Reduce: 2-14                      [-1, 768]                 --
|    └─LayerNorm: 2-15                   [-1, 768]                 1,536
|    └─Linear: 2-16                      [-1, 100]                 76,900
==========================================================================================
Total params: 85,723,492
Trainable params: 85,723,492
Non-trainable params: 0
Total mult-adds (M): 456.75
==========================================================================================
Input size (MB): 0.57
Forward/backward pass size (MB): 1.16
Params size (MB): 327.01
Estimated Total Size (MB): 328.74
==========================================================================================

 ==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─PatchEmbedding: 1-1                    [-1, 197, 768]            --
|    └─Sequential: 2-1                   [-1, 196, 768]            --
|    |    └─Conv2d: 3-1                  [-1, 768, 14, 14]         590,592
|    |    └─Rearrange: 3-2               [-1, 196, 768]            --
├─TransformerEncoder: 1-2                [-1, 197, 768]            --
|    └─TransformerEncoderBlock: 2-2      [-1, 197, 768]            --
|    |    └─Residual: 3-3                [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-4                [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-3      [-1, 197, 768]            --
|    |    └─Residual: 3-5                [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-6                [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-4      [-1, 197, 768]            --
|    |    └─Residual: 3-7                [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-8                [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-5      [-1, 197, 768]            --
|    |    └─Residual: 3-9                [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-10               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-6      [-1, 197, 768]            --
|    |    └─Residual: 3-11               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-12               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-7      [-1, 197, 768]            --
|    |    └─Residual: 3-13               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-14               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-8      [-1, 197, 768]            --
|    |    └─Residual: 3-15               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-16               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-9      [-1, 197, 768]            --
|    |    └─Residual: 3-17               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-18               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-10     [-1, 197, 768]            --
|    |    └─Residual: 3-19               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-20               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-11     [-1, 197, 768]            --
|    |    └─Residual: 3-21               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-22               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-12     [-1, 197, 768]            --
|    |    └─Residual: 3-23               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-24               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-13     [-1, 197, 768]            --
|    |    └─Residual: 3-25               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-26               [-1, 197, 768]            4,723,968
├─ClassificationHead: 1-3                [-1, 100]                 --
|    └─Reduce: 2-14                      [-1, 768]                 --
|    └─LayerNorm: 2-15                   [-1, 768]                 1,536
|    └─Linear: 2-16                      [-1, 100]                 76,900
==========================================================================================
Total params: 85,723,492
Trainable params: 85,723,492
Non-trainable params: 0
Total mult-adds (M): 456.75
==========================================================================================
Input size (MB): 0.57
Forward/backward pass size (MB): 1.16
Params size (MB): 327.01
Estimated Total Size (MB): 328.74
========================================================================================== 

with ImageNet 100


EXP org_architecture: Original VIT on imagenet100 with depth 12 and LEARNIGN_RATE 0.0003



wandb: Currently logged in as: jashpatel8561 (maa_64). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.5
wandb: Run data is saved locally in /scratch/data/m22cs061/VIT_for_smallDB/ORG/wandb/run-20240824_130944-7igj9lum
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run org_architecture_imagenet100_Lr_3e-4_EMB_768_patch_16_depth_12
wandb: ⭐️ View project at https://wandb.ai/maa_64/vit-small-data
wandb: 🚀 View run at https://wandb.ai/maa_64/vit-small-data/runs/7igj9lum
  0%|          | 0/100 [00:00<?, ?it/s]
Epoch: 1
Train Loss: 4.58064  Test Loss: 4.51834  ||  Train Accuray: 0.01606  Test Accuray: 0.00403
  1%|          | 1/100 [37:51<62:28:43, 2271.96s/it]
Epoch: 2
Train Loss: 4.47163  Test Loss: 4.39504  ||  Train Accuray: 0.02781  Test Accuray: 0.00519
  2%|▏         | 2/100 [1:12:31<58:46:12, 2158.90s/it]
Epoch: 3
Train Loss: 4.38297  Test Loss: 4.33992  ||  Train Accuray: 0.03224  Test Accuray: 0.00594
  3%|▎         | 3/100 [1:46:42<56:50:04, 2109.33s/it]
Epoch: 4
Train Loss: 4.34396  Test Loss: 4.31211  ||  Train Accuray: 0.03425  Test Accuray: 0.00594
  4%|▍         | 4/100 [2:20:54<55:39:09, 2086.97s/it]
Epoch: 5
Train Loss: 4.32219  Test Loss: 4.29803  ||  Train Accuray: 0.03638  Test Accuray: 0.00477
  5%|▌         | 5/100 [2:55:21<54:52:53, 2079.72s/it]
Epoch: 6
Train Loss: 4.30979  Test Loss: 4.28265  ||  Train Accuray: 0.03750  Test Accuray: 0.00538
  6%|▌         | 6/100 [3:29:37<54:05:27, 2071.57s/it]
Epoch: 7
Train Loss: 4.30114  Test Loss: 4.27509  ||  Train Accuray: 0.03741  Test Accuray: 0.00493
  7%|▋         | 7/100 [4:04:05<53:29:19, 2070.53s/it]
Epoch: 8
Train Loss: 4.29566  Test Loss: 4.27106  ||  Train Accuray: 0.03741  Test Accuray: 0.00512
  8%|▊         | 8/100 [4:38:38<52:55:43, 2071.13s/it]
Epoch: 9
Train Loss: 4.29234  Test Loss: 4.26948  ||  Train Accuray: 0.03831  Test Accuray: 0.00525
  9%|▉         | 9/100 [5:13:09<52:21:19, 2071.21s/it]
Epoch: 10
Train Loss: 4.28991  Test Loss: 4.26723  ||  Train Accuray: 0.03838  Test Accuray: 0.00461
 10%|█         | 10/100 [5:47:44<51:48:24, 2072.28s/it]