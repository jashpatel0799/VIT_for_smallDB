Wed Aug  7 22:33:48 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:B7:00.0 Off |                    0 |
| N/A   37C    P0             55W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+


Experiment Name: org_architecture
Experiment Details: base vit architecture Residual only at Multi head attention and norm layer only at Feed Forwoard Layer (NL,FF,DropL)


Dataset Name: cifar10
Seed: 64
Batch Size: 64
Number of Epochs: 100
Learning Rate: 3e-4
Input Channel: 3
Patch Size: 16
Embedding Size: 768
Input Image Size: 224
ViT Depth: 12
Number of Classes: 10
WandB Project: vit-small-data
WandB Run Name: org_architecture_cifar10_Lr_3e-4_EMB_768_patch_16_depth_12
Output Directory: results


===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
├─PatchEmbedding: 1-1                         [-1, 197, 768]            --
|    └─Sequential: 2-1                        [-1, 196, 768]            --
|    |    └─Conv2d: 3-1                       [-1, 768, 14, 14]         590,592
|    |    └─Rearrange: 3-2                    [-1, 196, 768]            --
├─TransformerEncoder: 1-2                     [-1, 197, 768]            --
|    └─TransformerEncoderBlock: 2-2           [-1, 197, 768]            --
|    |    └─Residual: 3-3                     [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-4                   [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-3           [-1, 197, 768]            --
|    |    └─Residual: 3-5                     [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-6                   [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-4           [-1, 197, 768]            --
|    |    └─Residual: 3-7                     [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-8                   [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-5           [-1, 197, 768]            --
|    |    └─Residual: 3-9                     [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-10                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-6           [-1, 197, 768]            --
|    |    └─Residual: 3-11                    [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-12                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-7           [-1, 197, 768]            --
|    |    └─Residual: 3-13                    [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-14                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-8           [-1, 197, 768]            --
|    |    └─Residual: 3-15                    [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-16                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-9           [-1, 197, 768]            --
|    |    └─Residual: 3-17                    [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-18                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-10          [-1, 197, 768]            --
|    |    └─Residual: 3-19                    [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-20                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-11          [-1, 197, 768]            --
|    |    └─Residual: 3-21                    [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-22                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-12          [-1, 197, 768]            --
|    |    └─Residual: 3-23                    [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-24                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-13          [-1, 197, 768]            --
|    |    └─Residual: 3-25                    [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-26                  [-1, 197, 768]            4,723,968
├─ClassificationHead: 1-3                     [-1, 10]                  --
|    └─Reduce: 2-14                           [-1, 768]                 --
|    └─LayerNorm: 2-15                        [-1, 768]                 1,536
|    └─Linear: 2-16                           [-1, 10]                  7,690
===============================================================================================
Total params: 85,635,850
Trainable params: 85,635,850
Non-trainable params: 0
Total mult-adds (M): 456.58
===============================================================================================
Input size (MB): 0.57
Forward/backward pass size (MB): 15.01
Params size (MB): 326.67
Estimated Total Size (MB): 342.25
===============================================================================================

 ===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
├─PatchEmbedding: 1-1                         [-1, 197, 768]            --
|    └─Sequential: 2-1                        [-1, 196, 768]            --
|    |    └─Conv2d: 3-1                       [-1, 768, 14, 14]         590,592
|    |    └─Rearrange: 3-2                    [-1, 196, 768]            --
├─TransformerEncoder: 1-2                     [-1, 197, 768]            --
|    └─TransformerEncoderBlock: 2-2           [-1, 197, 768]            --
|    |    └─Residual: 3-3                     [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-4                   [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-3           [-1, 197, 768]            --
|    |    └─Residual: 3-5                     [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-6                   [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-4           [-1, 197, 768]            --
|    |    └─Residual: 3-7                     [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-8                   [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-5           [-1, 197, 768]            --
|    |    └─Residual: 3-9                     [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-10                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-6           [-1, 197, 768]            --
|    |    └─Residual: 3-11                    [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-12                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-7           [-1, 197, 768]            --
|    |    └─Residual: 3-13                    [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-14                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-8           [-1, 197, 768]            --
|    |    └─Residual: 3-15                    [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-16                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-9           [-1, 197, 768]            --
|    |    └─Residual: 3-17                    [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-18                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-10          [-1, 197, 768]            --
|    |    └─Residual: 3-19                    [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-20                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-11          [-1, 197, 768]            --
|    |    └─Residual: 3-21                    [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-22                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-12          [-1, 197, 768]            --
|    |    └─Residual: 3-23                    [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-24                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-13          [-1, 197, 768]            --
|    |    └─Residual: 3-25                    [-1, 197, 768]            2,362,368
|    |    └─Sequential: 3-26                  [-1, 197, 768]            4,723,968
├─ClassificationHead: 1-3                     [-1, 10]                  --
|    └─Reduce: 2-14                           [-1, 768]                 --
|    └─LayerNorm: 2-15                        [-1, 768]                 1,536
|    └─Linear: 2-16                           [-1, 10]                  7,690
===============================================================================================
Total params: 85,635,850
Trainable params: 85,635,850
Non-trainable params: 0
Total mult-adds (M): 456.58
===============================================================================================
Input size (MB): 0.57
Forward/backward pass size (MB): 15.01
Params size (MB): 326.67
Estimated Total Size (MB): 342.25
=============================================================================================== 

With CIFAR10
Files already downloaded and verified
Files already downloaded and verified


EXP org_architecture: Original VIT on cifar10 with depth 12 and LEARNIGN_RATE 0.0003



wandb: Currently logged in as: jashpatel8561 (maa_64). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.5
wandb: Run data is saved locally in /scratch/data/m22cs061/VIT_for_smallDB/ORG/wandb/run-20240807_223400-ky8tsa0x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run org_architecture_cifar10_Lr_3e-4_EMB_768_patch_16_depth_12
wandb: ⭐️ View project at https://wandb.ai/maa_64/vit-small-data
wandb: 🚀 View run at https://wandb.ai/maa_64/vit-small-data/runs/ky8tsa0x
  0%|          | 0/100 [00:00<?, ?it/s]
Epoch: 1
Train Loss: 2.26394  Test Loss: 2.16768  ||  Train Accuray: 0.13852  Test Accuray: 0.18530
  1%|          | 1/100 [07:47<12:50:35, 467.03s/it]
Epoch: 2
Train Loss: 2.14345  Test Loss: 2.10777  ||  Train Accuray: 0.18976  Test Accuray: 0.18056
  2%|▏         | 2/100 [15:26<12:35:52, 462.78s/it]
Epoch: 3
Train Loss: 2.08230  Test Loss: 2.11761  ||  Train Accuray: 0.22077  Test Accuray: 0.19501
  3%|▎         | 3/100 [23:09<12:27:45, 462.53s/it]
Epoch: 4
Train Loss: 2.04501  Test Loss: 2.12453  ||  Train Accuray: 0.23615  Test Accuray: 0.19913
  4%|▍         | 4/100 [30:46<12:16:35, 460.37s/it]
Epoch: 5
Train Loss: 2.00953  Test Loss: 2.09266  ||  Train Accuray: 0.25576  Test Accuray: 0.22899
  5%|▌         | 5/100 [38:24<12:07:50, 459.69s/it]
Epoch: 6
Train Loss: 1.96870  Test Loss: 2.08245  ||  Train Accuray: 0.27042  Test Accuray: 0.26023
  6%|▌         | 6/100 [46:00<11:58:10, 458.40s/it]
Epoch: 7
Train Loss: 1.92939  Test Loss: 2.06989  ||  Train Accuray: 0.29277  Test Accuray: 0.26199
  7%|▋         | 7/100 [53:41<11:51:37, 459.11s/it]
Epoch: 8
Train Loss: 1.87787  Test Loss: 1.92611  ||  Train Accuray: 0.31462  Test Accuray: 0.29882
  8%|▊         | 8/100 [1:01:19<11:43:50, 459.03s/it]
Epoch: 9
Train Loss: 1.82911  Test Loss: 1.89608  ||  Train Accuray: 0.33391  Test Accuray: 0.33435
  9%|▉         | 9/100 [1:09:01<11:37:17, 459.76s/it]
Epoch: 10
Train Loss: 1.78790  Test Loss: 1.75675  ||  Train Accuray: 0.35064  Test Accuray: 0.36986
 10%|█         | 10/100 [1:16:41<11:29:41, 459.79s/it]
Epoch: 11
Train Loss: 1.75462  Test Loss: 1.83868  ||  Train Accuray: 0.36354  Test Accuray: 0.35045
 11%|█         | 11/100 [1:24:24<11:23:28, 460.77s/it]
Epoch: 12
Train Loss: 1.73323  Test Loss: 1.76781  ||  Train Accuray: 0.37600  Test Accuray: 0.37486
 12%|█▏        | 12/100 [1:32:04<11:15:29, 460.56s/it]
Epoch: 13
Train Loss: 1.71536  Test Loss: 1.86599  ||  Train Accuray: 0.37921  Test Accuray: 0.35615
 13%|█▎        | 13/100 [1:39:46<11:08:31, 461.06s/it]
Epoch: 14
Train Loss: 1.69873  Test Loss: 1.68845  ||  Train Accuray: 0.38824  Test Accuray: 0.39513
 14%|█▍        | 14/100 [1:47:25<11:00:07, 460.56s/it]
Epoch: 15
Train Loss: 1.68185  Test Loss: 1.68449  ||  Train Accuray: 0.39078  Test Accuray: 0.39170
 15%|█▌        | 15/100 [1:55:05<10:52:06, 460.31s/it]
Epoch: 16
Train Loss: 1.66755  Test Loss: 1.72516  ||  Train Accuray: 0.39775  Test Accuray: 0.38159
 16%|█▌        | 16/100 [2:02:43<10:43:16, 459.48s/it]
Epoch: 17
Train Loss: 1.65019  Test Loss: 1.70548  ||  Train Accuray: 0.40196  Test Accuray: 0.39388
 17%|█▋        | 17/100 [2:10:24<10:36:29, 460.11s/it]
Epoch: 18
Train Loss: 1.63877  Test Loss: 1.63740  ||  Train Accuray: 0.40761  Test Accuray: 0.40910
 18%|█▊        | 18/100 [2:18:04<10:28:42, 460.03s/it]
Epoch: 19
Train Loss: 1.62547  Test Loss: 1.73119  ||  Train Accuray: 0.41297  Test Accuray: 0.37769
 19%|█▉        | 19/100 [2:25:43<10:20:42, 459.79s/it]
Epoch: 20
Train Loss: 1.61212  Test Loss: 1.58795  ||  Train Accuray: 0.41547  Test Accuray: 0.42505
 20%|██        | 20/100 [2:33:25<10:13:46, 460.33s/it]
Epoch: 21
Train Loss: 1.59854  Test Loss: 1.65785  ||  Train Accuray: 0.41908  Test Accuray: 0.40815
 21%|██        | 21/100 [2:41:04<10:05:42, 460.03s/it]
Epoch: 22
Train Loss: 1.58866  Test Loss: 1.60029  ||  Train Accuray: 0.42592  Test Accuray: 0.41785
 22%|██▏       | 22/100 [2:48:46<9:58:52, 460.67s/it] 
Epoch: 23
Train Loss: 1.57371  Test Loss: 1.64810  ||  Train Accuray: 0.43061  Test Accuray: 0.41584
 23%|██▎       | 23/100 [2:56:29<9:51:45, 461.12s/it]
Epoch: 24
Train Loss: 1.56545  Test Loss: 1.55410  ||  Train Accuray: 0.43344  Test Accuray: 0.44242
 24%|██▍       | 24/100 [3:04:12<9:44:58, 461.82s/it]
Epoch: 25
Train Loss: 1.55189  Test Loss: 1.62163  ||  Train Accuray: 0.43892  Test Accuray: 0.42130
 25%|██▌       | 25/100 [3:11:50<9:36:01, 460.82s/it]
Epoch: 26
Train Loss: 1.53806  Test Loss: 1.53379  ||  Train Accuray: 0.44279  Test Accuray: 0.44756
 26%|██▌       | 26/100 [3:19:27<9:26:37, 459.42s/it]
Epoch: 27
Train Loss: 1.53206  Test Loss: 1.51161  ||  Train Accuray: 0.44493  Test Accuray: 0.45376
 27%|██▋       | 27/100 [3:27:09<9:19:53, 460.19s/it]
Epoch: 28
Train Loss: 1.51686  Test Loss: 1.49544  ||  Train Accuray: 0.44577  Test Accuray: 0.45518
 28%|██▊       | 28/100 [3:34:55<9:14:22, 461.98s/it]
Epoch: 29
Train Loss: 1.50946  Test Loss: 1.47004  ||  Train Accuray: 0.45266  Test Accuray: 0.46380
 29%|██▉       | 29/100 [3:42:41<9:08:06, 463.19s/it]
Epoch: 30
Train Loss: 1.49555  Test Loss: 1.49546  ||  Train Accuray: 0.45882  Test Accuray: 0.45378
 30%|███       | 30/100 [3:50:28<9:01:50, 464.44s/it]
Epoch: 31
Train Loss: 1.48497  Test Loss: 1.49036  ||  Train Accuray: 0.45879  Test Accuray: 0.46007
 31%|███       | 31/100 [3:58:15<8:55:05, 465.30s/it]
Epoch: 32
Train Loss: 1.47417  Test Loss: 1.46990  ||  Train Accuray: 0.46298  Test Accuray: 0.46774
 32%|███▏      | 32/100 [4:06:02<8:47:38, 465.57s/it]
Epoch: 33
Train Loss: 1.46382  Test Loss: 1.44030  ||  Train Accuray: 0.46767  Test Accuray: 0.47540
 33%|███▎      | 33/100 [4:13:46<8:39:33, 465.27s/it]
Epoch: 34
Train Loss: 1.45354  Test Loss: 1.45203  ||  Train Accuray: 0.47247  Test Accuray: 0.48194
 34%|███▍      | 34/100 [4:21:27<8:30:10, 463.79s/it]
Epoch: 35
Train Loss: 1.44579  Test Loss: 1.45538  ||  Train Accuray: 0.47645  Test Accuray: 0.47072
 35%|███▌      | 35/100 [4:29:04<8:20:24, 461.91s/it]
Epoch: 36
Train Loss: 1.43792  Test Loss: 1.42275  ||  Train Accuray: 0.47866  Test Accuray: 0.47858
 36%|███▌      | 36/100 [4:36:50<8:14:01, 463.14s/it]
Epoch: 37
Train Loss: 1.43024  Test Loss: 1.48496  ||  Train Accuray: 0.48420  Test Accuray: 0.46350
 37%|███▋      | 37/100 [4:44:36<8:07:03, 463.86s/it]
Epoch: 38
Train Loss: 1.42067  Test Loss: 1.44090  ||  Train Accuray: 0.48829  Test Accuray: 0.47813
 38%|███▊      | 38/100 [4:52:18<7:58:45, 463.32s/it]
Epoch: 39
Train Loss: 1.41629  Test Loss: 1.57865  ||  Train Accuray: 0.48573  Test Accuray: 0.45189
 39%|███▉      | 39/100 [5:00:01<7:51:07, 463.40s/it]
Epoch: 40
Train Loss: 1.40697  Test Loss: 1.44594  ||  Train Accuray: 0.48885  Test Accuray: 0.47905
 40%|████      | 40/100 [5:07:45<7:43:32, 463.54s/it]
Epoch: 41
Train Loss: 1.40388  Test Loss: 1.44536  ||  Train Accuray: 0.49307  Test Accuray: 0.48100
 41%|████      | 41/100 [5:15:30<7:36:13, 463.96s/it]
Epoch: 42
Train Loss: 1.39596  Test Loss: 1.38288  ||  Train Accuray: 0.49629  Test Accuray: 0.49689
 42%|████▏     | 42/100 [5:23:13<7:28:17, 463.74s/it]
Epoch: 43
Train Loss: 1.39060  Test Loss: 1.41792  ||  Train Accuray: 0.49614  Test Accuray: 0.49257
 43%|████▎     | 43/100 [5:31:00<7:21:16, 464.50s/it]
Epoch: 44
Train Loss: 1.38579  Test Loss: 1.41830  ||  Train Accuray: 0.49625  Test Accuray: 0.49455
 44%|████▍     | 44/100 [5:38:40<7:12:29, 463.39s/it]
Epoch: 45
Train Loss: 1.37812  Test Loss: 1.37163  ||  Train Accuray: 0.50287  Test Accuray: 0.50653
 45%|████▌     | 45/100 [5:46:18<7:03:18, 461.79s/it]
Epoch: 46
Train Loss: 1.37403  Test Loss: 1.36134  ||  Train Accuray: 0.50472  Test Accuray: 0.50581
 46%|████▌     | 46/100 [5:53:58<6:55:07, 461.25s/it]
Epoch: 47
Train Loss: 1.36787  Test Loss: 1.40042  ||  Train Accuray: 0.50439  Test Accuray: 0.49392
 47%|████▋     | 47/100 [6:01:42<6:48:08, 462.05s/it]
Epoch: 48
Train Loss: 1.36539  Test Loss: 1.42913  ||  Train Accuray: 0.50824  Test Accuray: 0.48705
 48%|████▊     | 48/100 [6:09:24<6:40:15, 461.84s/it]
Epoch: 49
Train Loss: 1.35807  Test Loss: 1.35437  ||  Train Accuray: 0.50588  Test Accuray: 0.51367
 49%|████▉     | 49/100 [6:17:07<6:32:59, 462.35s/it]
Epoch: 50
Train Loss: 1.35863  Test Loss: 1.38524  ||  Train Accuray: 0.50772  Test Accuray: 0.50568
 50%|█████     | 50/100 [6:24:53<6:26:13, 463.47s/it]
Epoch: 51
Train Loss: 1.35127  Test Loss: 1.37926  ||  Train Accuray: 0.51143  Test Accuray: 0.50443
 51%|█████     | 51/100 [6:32:38<6:18:41, 463.70s/it]
Epoch: 52
Train Loss: 1.35032  Test Loss: 1.38001  ||  Train Accuray: 0.51202  Test Accuray: 0.50480
 52%|█████▏    | 52/100 [6:40:21<6:10:51, 463.57s/it]
Epoch: 53
Train Loss: 1.34472  Test Loss: 1.38810  ||  Train Accuray: 0.51529  Test Accuray: 0.50531
 53%|█████▎    | 53/100 [6:48:03<6:02:50, 463.21s/it]
Epoch: 54
Train Loss: 1.34332  Test Loss: 1.38393  ||  Train Accuray: 0.51358  Test Accuray: 0.49959
 54%|█████▍    | 54/100 [6:55:47<5:55:15, 463.37s/it]
Epoch: 55
Train Loss: 1.34184  Test Loss: 1.46168  ||  Train Accuray: 0.51866  Test Accuray: 0.48447
 55%|█████▌    | 55/100 [7:03:29<5:47:14, 462.99s/it]
Epoch: 56
Train Loss: 1.33660  Test Loss: 1.49450  ||  Train Accuray: 0.51911  Test Accuray: 0.48227
 56%|█████▌    | 56/100 [7:11:09<5:38:52, 462.09s/it]
Epoch: 57
Train Loss: 1.33484  Test Loss: 1.42049  ||  Train Accuray: 0.52164  Test Accuray: 0.49753
 57%|█████▋    | 57/100 [7:18:48<5:30:35, 461.29s/it]
Epoch: 58
Train Loss: 1.33354  Test Loss: 1.34443  ||  Train Accuray: 0.52096  Test Accuray: 0.51526
 58%|█████▊    | 58/100 [7:26:26<5:22:08, 460.20s/it]
Epoch: 59
Train Loss: 1.32744  Test Loss: 1.38288  ||  Train Accuray: 0.52026  Test Accuray: 0.50183
 59%|█████▉    | 59/100 [7:34:03<5:13:47, 459.20s/it]
Epoch: 60
Train Loss: 1.32620  Test Loss: 1.36663  ||  Train Accuray: 0.52536  Test Accuray: 0.50968
 60%|██████    | 60/100 [7:41:40<5:05:41, 458.55s/it]
Epoch: 61
Train Loss: 1.32651  Test Loss: 1.38890  ||  Train Accuray: 0.52209  Test Accuray: 0.50782
 61%|██████    | 61/100 [7:49:16<4:57:31, 457.72s/it]
Epoch: 62
Train Loss: 1.31980  Test Loss: 1.35974  ||  Train Accuray: 0.52569  Test Accuray: 0.51130
 62%|██████▏   | 62/100 [7:56:53<4:49:41, 457.41s/it]
Epoch: 63
Train Loss: 1.32149  Test Loss: 1.39944  ||  Train Accuray: 0.52738  Test Accuray: 0.50295
 63%|██████▎   | 63/100 [8:04:30<4:42:04, 457.41s/it]
Epoch: 64
Train Loss: 1.31389  Test Loss: 1.30863  ||  Train Accuray: 0.52760  Test Accuray: 0.52569
 64%|██████▍   | 64/100 [8:12:09<4:34:43, 457.87s/it]
Epoch: 65
Train Loss: 1.31361  Test Loss: 1.30320  ||  Train Accuray: 0.52714  Test Accuray: 0.52628
 65%|██████▌   | 65/100 [8:19:47<4:27:09, 457.99s/it]
Epoch: 66
Train Loss: 1.31306  Test Loss: 1.31115  ||  Train Accuray: 0.52999  Test Accuray: 0.52557
 66%|██████▌   | 66/100 [8:27:26<4:19:43, 458.35s/it]
Epoch: 67
Train Loss: 1.30585  Test Loss: 1.37267  ||  Train Accuray: 0.53084  Test Accuray: 0.51529
 67%|██████▋   | 67/100 [8:35:06<4:12:21, 458.83s/it]
Epoch: 68
Train Loss: 1.29995  Test Loss: 1.33114  ||  Train Accuray: 0.53331  Test Accuray: 0.51589
 68%|██████▊   | 68/100 [8:42:46<4:04:49, 459.06s/it]
Epoch: 69
Train Loss: 1.30102  Test Loss: 1.37741  ||  Train Accuray: 0.53379  Test Accuray: 0.50557
 69%|██████▉   | 69/100 [8:50:25<3:57:12, 459.12s/it]
Epoch: 70
Train Loss: 1.29206  Test Loss: 1.34126  ||  Train Accuray: 0.53811  Test Accuray: 0.52112
 70%|███████   | 70/100 [8:58:04<3:49:31, 459.06s/it]
Epoch: 71
Train Loss: 1.29038  Test Loss: 1.30714  ||  Train Accuray: 0.53867  Test Accuray: 0.53392
 71%|███████   | 71/100 [9:05:39<3:41:18, 457.88s/it]
Epoch: 72
Train Loss: 1.28959  Test Loss: 1.37326  ||  Train Accuray: 0.53705  Test Accuray: 0.51224
 72%|███████▏  | 72/100 [9:13:17<3:33:36, 457.73s/it]
Epoch: 73
Train Loss: 1.28492  Test Loss: 1.34955  ||  Train Accuray: 0.53897  Test Accuray: 0.51906
 73%|███████▎  | 73/100 [9:20:57<3:26:18, 458.47s/it]
Epoch: 74
Train Loss: 1.28338  Test Loss: 1.31326  ||  Train Accuray: 0.53810  Test Accuray: 0.53262
 74%|███████▍  | 74/100 [9:28:33<3:18:23, 457.83s/it]
Epoch: 75
Train Loss: 1.28292  Test Loss: 1.34543  ||  Train Accuray: 0.53949  Test Accuray: 0.52408
 75%|███████▌  | 75/100 [9:36:09<3:10:29, 457.16s/it]
Epoch: 76
Train Loss: 1.28156  Test Loss: 1.29036  ||  Train Accuray: 0.54153  Test Accuray: 0.53127
 76%|███████▌  | 76/100 [9:43:46<3:02:51, 457.15s/it]
Epoch: 77
Train Loss: 1.27727  Test Loss: 1.25508  ||  Train Accuray: 0.54283  Test Accuray: 0.54753
 77%|███████▋  | 77/100 [9:51:23<2:55:12, 457.06s/it]
Epoch: 78
Train Loss: 1.27698  Test Loss: 1.29867  ||  Train Accuray: 0.54177  Test Accuray: 0.53957
 78%|███████▊  | 78/100 [9:58:58<2:47:26, 456.67s/it]
Epoch: 79
Train Loss: 1.27361  Test Loss: 1.31285  ||  Train Accuray: 0.54382  Test Accuray: 0.52848
 79%|███████▉  | 79/100 [10:06:35<2:39:48, 456.59s/it]
Epoch: 80
Train Loss: 1.27370  Test Loss: 1.37462  ||  Train Accuray: 0.54357  Test Accuray: 0.51142
 80%|████████  | 80/100 [10:14:13<2:32:22, 457.11s/it]
Epoch: 81
Train Loss: 1.27012  Test Loss: 1.35405  ||  Train Accuray: 0.54161  Test Accuray: 0.51638
 81%|████████  | 81/100 [10:21:50<2:24:46, 457.18s/it]
Epoch: 82
Train Loss: 1.26964  Test Loss: 1.35876  ||  Train Accuray: 0.54507  Test Accuray: 0.51574
 82%|████████▏ | 82/100 [10:29:28<2:17:12, 457.34s/it]
Epoch: 83
Train Loss: 1.26468  Test Loss: 1.38747  ||  Train Accuray: 0.54737  Test Accuray: 0.52265
 83%|████████▎ | 83/100 [10:37:06<2:09:39, 457.60s/it]
Epoch: 84
Train Loss: 1.26279  Test Loss: 1.34833  ||  Train Accuray: 0.54767  Test Accuray: 0.51781
 84%|████████▍ | 84/100 [10:44:44<2:01:59, 457.47s/it]
Epoch: 85
Train Loss: 1.26360  Test Loss: 1.26551  ||  Train Accuray: 0.54958  Test Accuray: 0.54809
 85%|████████▌ | 85/100 [10:52:20<1:54:18, 457.21s/it]
Epoch: 86
Train Loss: 1.26042  Test Loss: 1.26627  ||  Train Accuray: 0.54901  Test Accuray: 0.54173
 86%|████████▌ | 86/100 [10:59:58<1:46:42, 457.30s/it]
Epoch: 87
Train Loss: 1.25534  Test Loss: 1.26128  ||  Train Accuray: 0.55093  Test Accuray: 0.55151
 87%|████████▋ | 87/100 [11:07:35<1:39:03, 457.20s/it]
Epoch: 88
Train Loss: 1.25638  Test Loss: 1.29288  ||  Train Accuray: 0.55325  Test Accuray: 0.53281
 88%|████████▊ | 88/100 [11:15:10<1:31:19, 456.61s/it]
Epoch: 89
Train Loss: 1.25817  Test Loss: 1.26524  ||  Train Accuray: 0.54983  Test Accuray: 0.53955
 89%|████████▉ | 89/100 [11:22:47<1:23:43, 456.65s/it]
Epoch: 90
Train Loss: 1.24918  Test Loss: 1.32461  ||  Train Accuray: 0.55268  Test Accuray: 0.53028
 90%|█████████ | 90/100 [11:30:27<1:16:16, 457.64s/it]
Epoch: 91
Train Loss: 1.25449  Test Loss: 1.26370  ||  Train Accuray: 0.55095  Test Accuray: 0.54944
 91%|█████████ | 91/100 [11:38:02<1:08:31, 456.85s/it]
Epoch: 92
Train Loss: 1.24754  Test Loss: 1.36817  ||  Train Accuray: 0.55511  Test Accuray: 0.50654
 92%|█████████▏| 92/100 [11:45:38<1:00:52, 456.59s/it]
Epoch: 93
Train Loss: 1.24979  Test Loss: 1.28386  ||  Train Accuray: 0.55112  Test Accuray: 0.53986
 93%|█████████▎| 93/100 [11:53:17<53:22, 457.48s/it]  
Epoch: 94
Train Loss: 1.24514  Test Loss: 1.28308  ||  Train Accuray: 0.55154  Test Accuray: 0.53706
 94%|█████████▍| 94/100 [12:00:55<45:44, 457.50s/it]
Epoch: 95
Train Loss: 1.24215  Test Loss: 1.37763  ||  Train Accuray: 0.55474  Test Accuray: 0.50042
 95%|█████████▌| 95/100 [12:08:34<38:09, 457.99s/it]
Epoch: 96
Train Loss: 1.24709  Test Loss: 1.24744  ||  Train Accuray: 0.55377  Test Accuray: 0.55348
 96%|█████████▌| 96/100 [12:16:14<30:34, 458.68s/it]
Epoch: 97
Train Loss: 1.24366  Test Loss: 1.21781  ||  Train Accuray: 0.55224  Test Accuray: 0.55979
 97%|█████████▋| 97/100 [12:23:54<22:57, 459.10s/it]
Epoch: 98
Train Loss: 1.24459  Test Loss: 1.23330  ||  Train Accuray: 0.55417  Test Accuray: 0.55326
 98%|█████████▊| 98/100 [12:31:31<15:16, 458.36s/it]
Epoch: 99
Train Loss: 1.24170  Test Loss: 1.29438  ||  Train Accuray: 0.55515  Test Accuray: 0.52573
 99%|█████████▉| 99/100 [12:39:09<07:38, 458.42s/it]
Epoch: 100
Train Loss: 1.23976  Test Loss: 1.42167  ||  Train Accuray: 0.55611  Test Accuray: 0.50571
100%|██████████| 100/100 [12:46:50<00:00, 459.05s/it]100%|██████████| 100/100 [12:46:50<00:00, 460.10s/it]
wandb: - 0.027 MB of 0.027 MB uploadedwandb: \ 0.027 MB of 0.027 MB uploadedwandb: | 0.027 MB of 0.027 MB uploadedwandb: / 0.027 MB of 0.027 MB uploadedwandb: - 0.027 MB of 0.027 MB uploadedwandb: \ 0.031 MB of 0.038 MB uploadedwandb: | 0.046 MB of 0.046 MB uploadedwandb: / 0.046 MB of 0.046 MB uploadedwandb: - 0.046 MB of 0.046 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:     Test Accuracy ▁▁▂▃▄▄▅▅▅▅▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇██▇
wandb:         Test Loss ██▇▆▆▆▅▄▄▄▃▃▃▃▃▄▃▂▂▂▂▂▃▂▂▂▂▂▂▂▁▂▂▂▁▁▂▁▁▃
wandb: Training Accuracy ▁▂▃▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████████
wandb:     Training Loss █▇▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     Test Accuracy 0.50571
wandb:         Test Loss 1.42167
wandb: Training Accuracy 0.55611
wandb:     Training Loss 1.23976
wandb: 
wandb: 🚀 View run org_architecture_cifar10_Lr_3e-4_EMB_768_patch_16_depth_12 at: https://wandb.ai/maa_64/vit-small-data/runs/ky8tsa0x
wandb: ⭐️ View project at: https://wandb.ai/maa_64/vit-small-data
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240807_223400-ky8tsa0x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.

Saving Model At: save_model/vit_model_org_architecture_cifar10_0.0003_64.pth
