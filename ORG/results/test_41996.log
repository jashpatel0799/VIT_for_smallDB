Sat Sep 28 18:42:11 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:90:00.0 Off |                    0 |
| N/A   30C    P0             53W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+


Experiment Name: org_architecture
Experiment Model Number: 2
1. base vit architecture 
2. base vit architecture with RMS norm
Experiment Details: base vit architecture with RSM norm


Dataset Name: cifar10
Seed: 64
Batch Size: 64
Number of Epochs: 100
Learning Rate: 3e-4
Input Channel: 3
Patch Size: 16
Embedding Size: 768
Input Image Size: 224
ViT Depth: 12
Number of Classes: 100
WandB Project: vit-small-data
WandB Run Name: org_architecture_cifar10_Lr_3e-4_EMB_768_patch_16_depth_12
Output Directory: results


==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─PatchEmbedding: 1-1                    [-1, 197, 768]            --
|    └─Sequential: 2-1                   [-1, 196, 768]            --
|    |    └─Conv2d: 3-1                  [-1, 768, 14, 14]         590,592
|    |    └─Rearrange: 3-2               [-1, 196, 768]            --
├─TransformerEncoder: 1-2                [-1, 197, 768]            --
|    └─TransformerEncoderBlock: 2-2      [-1, 197, 768]            --
|    |    └─Residual: 3-3                [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-4                [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-3      [-1, 197, 768]            --
|    |    └─Residual: 3-5                [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-6                [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-4      [-1, 197, 768]            --
|    |    └─Residual: 3-7                [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-8                [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-5      [-1, 197, 768]            --
|    |    └─Residual: 3-9                [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-10               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-6      [-1, 197, 768]            --
|    |    └─Residual: 3-11               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-12               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-7      [-1, 197, 768]            --
|    |    └─Residual: 3-13               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-14               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-8      [-1, 197, 768]            --
|    |    └─Residual: 3-15               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-16               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-9      [-1, 197, 768]            --
|    |    └─Residual: 3-17               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-18               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-10     [-1, 197, 768]            --
|    |    └─Residual: 3-19               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-20               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-11     [-1, 197, 768]            --
|    |    └─Residual: 3-21               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-22               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-12     [-1, 197, 768]            --
|    |    └─Residual: 3-23               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-24               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-13     [-1, 197, 768]            --
|    |    └─Residual: 3-25               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-26               [-1, 197, 768]            4,723,968
├─ClassificationHead: 1-3                [-1, 100]                 --
|    └─Reduce: 2-14                      [-1, 768]                 --
|    └─LayerNorm: 2-15                   [-1, 768]                 1,536
|    └─Linear: 2-16                      [-1, 100]                 76,900
==========================================================================================
Total params: 85,723,492
Trainable params: 85,723,492
Non-trainable params: 0
Total mult-adds (M): 456.75
==========================================================================================
Input size (MB): 0.57
Forward/backward pass size (MB): 1.16
Params size (MB): 327.01
Estimated Total Size (MB): 328.74
==========================================================================================

 ==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─PatchEmbedding: 1-1                    [-1, 197, 768]            --
|    └─Sequential: 2-1                   [-1, 196, 768]            --
|    |    └─Conv2d: 3-1                  [-1, 768, 14, 14]         590,592
|    |    └─Rearrange: 3-2               [-1, 196, 768]            --
├─TransformerEncoder: 1-2                [-1, 197, 768]            --
|    └─TransformerEncoderBlock: 2-2      [-1, 197, 768]            --
|    |    └─Residual: 3-3                [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-4                [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-3      [-1, 197, 768]            --
|    |    └─Residual: 3-5                [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-6                [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-4      [-1, 197, 768]            --
|    |    └─Residual: 3-7                [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-8                [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-5      [-1, 197, 768]            --
|    |    └─Residual: 3-9                [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-10               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-6      [-1, 197, 768]            --
|    |    └─Residual: 3-11               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-12               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-7      [-1, 197, 768]            --
|    |    └─Residual: 3-13               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-14               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-8      [-1, 197, 768]            --
|    |    └─Residual: 3-15               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-16               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-9      [-1, 197, 768]            --
|    |    └─Residual: 3-17               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-18               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-10     [-1, 197, 768]            --
|    |    └─Residual: 3-19               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-20               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-11     [-1, 197, 768]            --
|    |    └─Residual: 3-21               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-22               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-12     [-1, 197, 768]            --
|    |    └─Residual: 3-23               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-24               [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-13     [-1, 197, 768]            --
|    |    └─Residual: 3-25               [-1, 197, 768]            2,363,904
|    |    └─Residual: 3-26               [-1, 197, 768]            4,723,968
├─ClassificationHead: 1-3                [-1, 100]                 --
|    └─Reduce: 2-14                      [-1, 768]                 --
|    └─LayerNorm: 2-15                   [-1, 768]                 1,536
|    └─Linear: 2-16                      [-1, 100]                 76,900
==========================================================================================
Total params: 85,723,492
Trainable params: 85,723,492
Non-trainable params: 0
Total mult-adds (M): 456.75
==========================================================================================
Input size (MB): 0.57
Forward/backward pass size (MB): 1.16
Params size (MB): 327.01
Estimated Total Size (MB): 328.74
========================================================================================== 



EXP org_architecture: Original VIT on cifar10 with depth 12 and LEARNIGN_RATE 0.0003



With CIFAR10
Files already downloaded and verified
Files already downloaded and verified
wandb: Currently logged in as: jashpatel8561 (maa_64). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.5
wandb: Run data is saved locally in /scratch/data/m22cs061/VIT_for_smallDB/ORG/wandb/run-20240928_184218-eugplg40
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run org_architecture_cifar10_Lr_3e-4_EMB_768_patch_16_depth_12
wandb: ⭐️ View project at https://wandb.ai/maa_64/vit-small-data
wandb: 🚀 View run at https://wandb.ai/maa_64/vit-small-data/runs/eugplg40
  0%|          | 0/100 [00:00<?, ?it/s]
Epoch: 1
Train Loss: 2.39195  Test Loss: 2.21419  ||  Train Accuray: 0.16048  Test Accuray: 0.19389
  1%|          | 1/100 [07:27<12:18:33, 447.61s/it]
Epoch: 2
Train Loss: 2.18263  Test Loss: 2.13672  ||  Train Accuray: 0.19829  Test Accuray: 0.22464
  2%|▏         | 2/100 [14:54<12:10:46, 447.42s/it]
Epoch: 3
Train Loss: 2.12891  Test Loss: 2.10844  ||  Train Accuray: 0.21266  Test Accuray: 0.20911
  3%|▎         | 3/100 [22:18<12:00:41, 445.79s/it]
Epoch: 4
Train Loss: 2.10080  Test Loss: 2.07744  ||  Train Accuray: 0.21823  Test Accuray: 0.22149
  4%|▍         | 4/100 [29:42<11:52:16, 445.17s/it]
Epoch: 5
Train Loss: 2.08741  Test Loss: 2.06930  ||  Train Accuray: 0.22253  Test Accuray: 0.24614
  5%|▌         | 5/100 [37:08<11:44:55, 445.22s/it]
Epoch: 6
Train Loss: 2.07848  Test Loss: 2.05964  ||  Train Accuray: 0.22654  Test Accuray: 0.23859
  6%|▌         | 6/100 [44:34<11:38:08, 445.62s/it]
Epoch: 7
Train Loss: 2.07163  Test Loss: 2.04978  ||  Train Accuray: 0.22691  Test Accuray: 0.24063
  7%|▋         | 7/100 [52:01<11:31:23, 446.06s/it]
Epoch: 8
Train Loss: 2.06711  Test Loss: 2.04898  ||  Train Accuray: 0.23205  Test Accuray: 0.23937
  8%|▊         | 8/100 [59:27<11:23:45, 445.92s/it]
Epoch: 9
Train Loss: 2.06242  Test Loss: 2.04393  ||  Train Accuray: 0.23300  Test Accuray: 0.25699
  9%|▉         | 9/100 [1:06:53<11:16:22, 445.96s/it]
Epoch: 10
Train Loss: 2.05847  Test Loss: 2.04512  ||  Train Accuray: 0.23557  Test Accuray: 0.24815
 10%|█         | 10/100 [1:14:19<11:08:50, 445.90s/it]
Epoch: 11
Train Loss: 2.05524  Test Loss: 2.03750  ||  Train Accuray: 0.24022  Test Accuray: 0.24580
 11%|█         | 11/100 [1:21:45<11:01:36, 446.02s/it]
Epoch: 12
Train Loss: 2.05283  Test Loss: 2.03882  ||  Train Accuray: 0.24063  Test Accuray: 0.24926
 12%|█▏        | 12/100 [1:29:11<10:54:13, 446.06s/it]
Epoch: 13
Train Loss: 2.04895  Test Loss: 2.03848  ||  Train Accuray: 0.24255  Test Accuray: 0.23886
 13%|█▎        | 13/100 [1:36:38<10:47:09, 446.32s/it]
Epoch: 14
Train Loss: 2.04709  Test Loss: 2.02786  ||  Train Accuray: 0.24261  Test Accuray: 0.27055
 14%|█▍        | 14/100 [1:44:04<10:39:48, 446.38s/it]
Epoch: 15
Train Loss: 2.04445  Test Loss: 2.03642  ||  Train Accuray: 0.24451  Test Accuray: 0.25305
 15%|█▌        | 15/100 [1:51:32<10:32:59, 446.81s/it]
Epoch: 16
Train Loss: 2.04175  Test Loss: 2.02479  ||  Train Accuray: 0.24581  Test Accuray: 0.26237
 16%|█▌        | 16/100 [1:58:59<10:25:41, 446.92s/it]
Epoch: 17
Train Loss: 2.04032  Test Loss: 2.02126  ||  Train Accuray: 0.24774  Test Accuray: 0.25758
 17%|█▋        | 17/100 [2:06:28<10:18:47, 447.32s/it]
Epoch: 18
Train Loss: 2.03706  Test Loss: 2.01666  ||  Train Accuray: 0.25037  Test Accuray: 0.26974
 18%|█▊        | 18/100 [2:13:56<10:11:34, 447.49s/it]
Epoch: 19
Train Loss: 2.03518  Test Loss: 2.01777  ||  Train Accuray: 0.24861  Test Accuray: 0.27495
 19%|█▉        | 19/100 [2:21:24<10:04:36, 447.86s/it]
Epoch: 20
Train Loss: 2.03349  Test Loss: 2.01336  ||  Train Accuray: 0.25483  Test Accuray: 0.27342
 20%|██        | 20/100 [2:28:52<9:57:13, 447.92s/it] 
Epoch: 21
Train Loss: 2.03102  Test Loss: 2.01316  ||  Train Accuray: 0.25534  Test Accuray: 0.27532
 21%|██        | 21/100 [2:36:21<9:49:59, 448.09s/it]
Epoch: 22
Train Loss: 2.02910  Test Loss: 2.01499  ||  Train Accuray: 0.25788  Test Accuray: 0.27534
 22%|██▏       | 22/100 [2:43:49<9:42:43, 448.25s/it]
Epoch: 23
Train Loss: 2.02858  Test Loss: 2.01637  ||  Train Accuray: 0.25795  Test Accuray: 0.26381
 23%|██▎       | 23/100 [2:51:18<9:35:29, 448.44s/it]
Epoch: 24
Train Loss: 2.02645  Test Loss: 2.01042  ||  Train Accuray: 0.25580  Test Accuray: 0.27214
 24%|██▍       | 24/100 [2:58:47<9:28:10, 448.55s/it]
Epoch: 25
Train Loss: 2.02548  Test Loss: 2.01143  ||  Train Accuray: 0.25878  Test Accuray: 0.25898
 25%|██▌       | 25/100 [3:06:16<9:20:48, 448.64s/it]
Epoch: 26
Train Loss: 2.02381  Test Loss: 2.01244  ||  Train Accuray: 0.26000  Test Accuray: 0.27212
 26%|██▌       | 26/100 [3:13:45<9:13:28, 448.76s/it]
Epoch: 27
Train Loss: 2.02225  Test Loss: 2.00863  ||  Train Accuray: 0.25764  Test Accuray: 0.26881
 27%|██▋       | 27/100 [3:21:14<9:06:03, 448.81s/it]
Epoch: 28
Train Loss: 2.02075  Test Loss: 2.00353  ||  Train Accuray: 0.26087  Test Accuray: 0.26725
 28%|██▊       | 28/100 [3:28:43<8:58:32, 448.78s/it]
Epoch: 29
Train Loss: 2.02067  Test Loss: 2.00351  ||  Train Accuray: 0.26008  Test Accuray: 0.27262
 29%|██▉       | 29/100 [3:36:11<8:50:57, 448.70s/it]
Epoch: 30
Train Loss: 2.01903  Test Loss: 1.99997  ||  Train Accuray: 0.26015  Test Accuray: 0.27734
 30%|███       | 30/100 [3:43:39<8:43:14, 448.49s/it]
Epoch: 31
Train Loss: 2.01843  Test Loss: 2.01402  ||  Train Accuray: 0.26469  Test Accuray: 0.25277
 31%|███       | 31/100 [3:51:07<8:35:36, 448.36s/it]
Epoch: 32
Train Loss: 2.01805  Test Loss: 2.00420  ||  Train Accuray: 0.26559  Test Accuray: 0.26414
 32%|███▏      | 32/100 [3:58:36<8:28:08, 448.36s/it]
Epoch: 33
Train Loss: 2.01794  Test Loss: 2.00552  ||  Train Accuray: 0.26347  Test Accuray: 0.26367
 33%|███▎      | 33/100 [4:06:04<8:20:43, 448.42s/it]
Epoch: 34
Train Loss: 2.01698  Test Loss: 2.01454  ||  Train Accuray: 0.26138  Test Accuray: 0.27033
 34%|███▍      | 34/100 [4:13:33<8:13:17, 448.44s/it]
Epoch: 35
Train Loss: 2.01706  Test Loss: 2.01657  ||  Train Accuray: 0.26207  Test Accuray: 0.26917
 35%|███▌      | 35/100 [4:21:01<8:05:45, 448.39s/it]
Epoch: 36
Train Loss: 2.01720  Test Loss: 2.00491  ||  Train Accuray: 0.26555  Test Accuray: 0.26949
 36%|███▌      | 36/100 [4:28:29<7:58:06, 448.22s/it]
Epoch: 37
Train Loss: 2.01593  Test Loss: 2.01133  ||  Train Accuray: 0.26498  Test Accuray: 0.26473
 37%|███▋      | 37/100 [4:35:56<7:50:18, 447.91s/it]
Epoch: 38
Train Loss: 2.01723  Test Loss: 1.99969  ||  Train Accuray: 0.26458  Test Accuray: 0.27373
 38%|███▊      | 38/100 [4:43:23<7:42:43, 447.79s/it]
Epoch: 39
Train Loss: 2.01552  Test Loss: 2.00529  ||  Train Accuray: 0.26109  Test Accuray: 0.27652
 39%|███▉      | 39/100 [4:50:51<7:35:07, 447.66s/it]
Epoch: 40
Train Loss: 2.01601  Test Loss: 2.00272  ||  Train Accuray: 0.26404  Test Accuray: 0.27289
 40%|████      | 40/100 [4:58:18<7:27:35, 447.59s/it]
Epoch: 41
Train Loss: 2.01514  Test Loss: 2.00215  ||  Train Accuray: 0.26470  Test Accuray: 0.28271
 41%|████      | 41/100 [5:05:45<7:19:55, 447.38s/it]
Epoch: 42
Train Loss: 2.01514  Test Loss: 2.00119  ||  Train Accuray: 0.26500  Test Accuray: 0.27217
 42%|████▏     | 42/100 [5:13:12<7:12:12, 447.12s/it]
Epoch: 43
Train Loss: 2.01491  Test Loss: 1.99953  ||  Train Accuray: 0.26779  Test Accuray: 0.27606
 43%|████▎     | 43/100 [5:20:38<7:04:25, 446.77s/it]
Epoch: 44
Train Loss: 2.01536  Test Loss: 2.00088  ||  Train Accuray: 0.26544  Test Accuray: 0.27370
 44%|████▍     | 44/100 [5:28:04<6:56:54, 446.68s/it]
Epoch: 45
Train Loss: 2.01565  Test Loss: 2.00968  ||  Train Accuray: 0.26381  Test Accuray: 0.26487
 45%|████▌     | 45/100 [5:35:30<6:49:10, 446.37s/it]
Epoch: 46
Train Loss: 2.01577  Test Loss: 2.01031  ||  Train Accuray: 0.26465  Test Accuray: 0.26019
 46%|████▌     | 46/100 [5:42:56<6:41:36, 446.23s/it]
Epoch: 47
Train Loss: 2.01543  Test Loss: 2.00818  ||  Train Accuray: 0.26542  Test Accuray: 0.27104
 47%|████▋     | 47/100 [5:50:21<6:33:49, 445.84s/it]
Epoch: 48
Train Loss: 2.01590  Test Loss: 2.00753  ||  Train Accuray: 0.26214  Test Accuray: 0.26486
 48%|████▊     | 48/100 [5:57:46<6:26:22, 445.81s/it]
Epoch: 49
Train Loss: 2.01706  Test Loss: 2.00231  ||  Train Accuray: 0.26327  Test Accuray: 0.27121
 49%|████▉     | 49/100 [6:05:12<6:18:47, 445.65s/it]
Epoch: 50
Train Loss: 2.01584  Test Loss: 2.00507  ||  Train Accuray: 0.26380  Test Accuray: 0.27060
 50%|█████     | 50/100 [6:12:37<6:11:13, 445.47s/it]
Epoch: 51
Train Loss: 2.01561  Test Loss: 2.00810  ||  Train Accuray: 0.26427  Test Accuray: 0.27120
 51%|█████     | 51/100 [6:20:02<6:03:41, 445.34s/it]
Epoch: 52
Train Loss: 2.01655  Test Loss: 2.00683  ||  Train Accuray: 0.26656  Test Accuray: 0.26460
 52%|█████▏    | 52/100 [6:27:27<5:56:11, 445.23s/it]
Epoch: 53
Train Loss: 2.01672  Test Loss: 2.00349  ||  Train Accuray: 0.26315  Test Accuray: 0.27073
 53%|█████▎    | 53/100 [6:34:52<5:48:43, 445.18s/it]
Epoch: 54
Train Loss: 2.01691  Test Loss: 2.00845  ||  Train Accuray: 0.26287  Test Accuray: 0.26793
 54%|█████▍    | 54/100 [6:42:16<5:41:12, 445.06s/it]
Epoch: 55
Train Loss: 2.01666  Test Loss: 2.00721  ||  Train Accuray: 0.26553  Test Accuray: 0.26767
 55%|█████▌    | 55/100 [6:49:41<5:33:42, 444.94s/it]
Epoch: 56
Train Loss: 2.01724  Test Loss: 2.00977  ||  Train Accuray: 0.26294  Test Accuray: 0.27157
 56%|█████▌    | 56/100 [6:57:06<5:26:13, 444.85s/it]
Epoch: 57
Train Loss: 2.01747  Test Loss: 2.00409  ||  Train Accuray: 0.26417  Test Accuray: 0.27577
 57%|█████▋    | 57/100 [7:04:31<5:18:48, 444.84s/it]
Epoch: 58
Train Loss: 2.01840  Test Loss: 2.02392  ||  Train Accuray: 0.26295  Test Accuray: 0.25841
 58%|█████▊    | 58/100 [7:11:55<5:11:22, 444.83s/it]
Epoch: 59
Train Loss: 2.01803  Test Loss: 2.00834  ||  Train Accuray: 0.26298  Test Accuray: 0.26539
 59%|█████▉    | 59/100 [7:19:20<5:03:58, 444.84s/it]
Epoch: 60
Train Loss: 2.01872  Test Loss: 2.00939  ||  Train Accuray: 0.26298  Test Accuray: 0.27296
 60%|██████    | 60/100 [7:26:46<4:56:39, 444.99s/it]
Epoch: 61
Train Loss: 2.01856  Test Loss: 2.00611  ||  Train Accuray: 0.26536  Test Accuray: 0.27498
 61%|██████    | 61/100 [7:34:11<4:49:17, 445.06s/it]
Epoch: 62
Train Loss: 2.01871  Test Loss: 2.00774  ||  Train Accuray: 0.26369  Test Accuray: 0.27054
 62%|██████▏   | 62/100 [7:41:36<4:41:49, 445.00s/it]
Epoch: 63
Train Loss: 2.01873  Test Loss: 2.01174  ||  Train Accuray: 0.26268  Test Accuray: 0.26694
 63%|██████▎   | 63/100 [7:49:00<4:34:22, 444.93s/it]
Epoch: 64
Train Loss: 2.01957  Test Loss: 2.00992  ||  Train Accuray: 0.26321  Test Accuray: 0.27329
 64%|██████▍   | 64/100 [7:56:25<4:26:56, 444.90s/it]
Epoch: 65
Train Loss: 2.01982  Test Loss: 2.00673  ||  Train Accuray: 0.26238  Test Accuray: 0.27853
 65%|██████▌   | 65/100 [8:03:50<4:19:28, 444.82s/it]
Epoch: 66
Train Loss: 2.01970  Test Loss: 2.01110  ||  Train Accuray: 0.26310  Test Accuray: 0.26922
 66%|██████▌   | 66/100 [8:11:15<4:12:02, 444.79s/it]
Epoch: 67
Train Loss: 2.02080  Test Loss: 2.01167  ||  Train Accuray: 0.26474  Test Accuray: 0.26867
 67%|██████▋   | 67/100 [8:18:40<4:04:40, 444.87s/it]
Epoch: 68
Train Loss: 2.02047  Test Loss: 2.01485  ||  Train Accuray: 0.26144  Test Accuray: 0.26189
 68%|██████▊   | 68/100 [8:26:05<3:57:16, 444.89s/it]
Epoch: 69
Train Loss: 2.02027  Test Loss: 2.01049  ||  Train Accuray: 0.26433  Test Accuray: 0.26884
 69%|██████▉   | 69/100 [8:33:29<3:49:48, 444.78s/it]
Epoch: 70
Train Loss: 2.02057  Test Loss: 2.01077  ||  Train Accuray: 0.26069  Test Accuray: 0.27372
 70%|███████   | 70/100 [8:40:54<3:42:23, 444.80s/it]
Epoch: 71
Train Loss: 2.02137  Test Loss: 2.00841  ||  Train Accuray: 0.26123  Test Accuray: 0.27066
 71%|███████   | 71/100 [8:48:19<3:34:59, 444.82s/it]
Epoch: 72
Train Loss: 2.02156  Test Loss: 2.01701  ||  Train Accuray: 0.26236  Test Accuray: 0.27094
 72%|███████▏  | 72/100 [8:55:44<3:27:35, 444.84s/it]
Epoch: 73
Train Loss: 2.02197  Test Loss: 2.00796  ||  Train Accuray: 0.26052  Test Accuray: 0.27434
 73%|███████▎  | 73/100 [9:03:08<3:20:06, 444.70s/it]
Epoch: 74
Train Loss: 2.02270  Test Loss: 2.01216  ||  Train Accuray: 0.26272  Test Accuray: 0.27071
 74%|███████▍  | 74/100 [9:10:32<3:12:38, 444.55s/it]
Epoch: 75
Train Loss: 2.02203  Test Loss: 2.01650  ||  Train Accuray: 0.26459  Test Accuray: 0.26518
 75%|███████▌  | 75/100 [9:17:57<3:05:11, 444.46s/it]
Epoch: 76
Train Loss: 2.02288  Test Loss: 2.01322  ||  Train Accuray: 0.26409  Test Accuray: 0.26353
 76%|███████▌  | 76/100 [9:25:21<2:57:46, 444.46s/it]
Epoch: 77
Train Loss: 2.02241  Test Loss: 2.00909  ||  Train Accuray: 0.26199  Test Accuray: 0.27399
 77%|███████▋  | 77/100 [9:32:45<2:50:20, 444.39s/it]
Epoch: 78
Train Loss: 2.02335  Test Loss: 2.01241  ||  Train Accuray: 0.26136  Test Accuray: 0.26972
 78%|███████▊  | 78/100 [9:40:10<2:42:56, 444.39s/it]
Epoch: 79
Train Loss: 2.02394  Test Loss: 2.01211  ||  Train Accuray: 0.25995  Test Accuray: 0.26638
 79%|███████▉  | 79/100 [9:47:34<2:35:33, 444.45s/it]
Epoch: 80
Train Loss: 2.02415  Test Loss: 2.01680  ||  Train Accuray: 0.26123  Test Accuray: 0.26799
 80%|████████  | 80/100 [9:54:59<2:28:08, 444.43s/it]
Epoch: 81
Train Loss: 2.02411  Test Loss: 2.01232  ||  Train Accuray: 0.26249  Test Accuray: 0.27138
 81%|████████  | 81/100 [10:02:23<2:20:43, 444.39s/it]
Epoch: 82
Train Loss: 2.02435  Test Loss: 2.01219  ||  Train Accuray: 0.26276  Test Accuray: 0.26234
 82%|████████▏ | 82/100 [10:09:47<2:13:17, 444.31s/it]
Epoch: 83
Train Loss: 2.02401  Test Loss: 2.01089  ||  Train Accuray: 0.26359  Test Accuray: 0.26834
 83%|████████▎ | 83/100 [10:17:12<2:05:54, 444.37s/it]
Epoch: 84
Train Loss: 2.02428  Test Loss: 2.01079  ||  Train Accuray: 0.26027  Test Accuray: 0.27104
 84%|████████▍ | 84/100 [10:24:36<1:58:29, 444.36s/it]
Epoch: 85
Train Loss: 2.02506  Test Loss: 2.01662  ||  Train Accuray: 0.26007  Test Accuray: 0.26592
 85%|████████▌ | 85/100 [10:32:00<1:51:06, 444.41s/it]
Epoch: 86
Train Loss: 2.02495  Test Loss: 2.01855  ||  Train Accuray: 0.26388  Test Accuray: 0.27104
 86%|████████▌ | 86/100 [10:39:25<1:43:42, 444.43s/it]
Epoch: 87
Train Loss: 2.02586  Test Loss: 2.01486  ||  Train Accuray: 0.26238  Test Accuray: 0.26892
 87%|████████▋ | 87/100 [10:46:49<1:36:16, 444.38s/it]
Epoch: 88
Train Loss: 2.02566  Test Loss: 2.01398  ||  Train Accuray: 0.26046  Test Accuray: 0.26953
 88%|████████▊ | 88/100 [10:54:14<1:28:53, 444.44s/it]
Epoch: 89
Train Loss: 2.02610  Test Loss: 2.01358  ||  Train Accuray: 0.26043  Test Accuray: 0.27408
 89%|████████▉ | 89/100 [11:01:38<1:21:28, 444.45s/it]
Epoch: 90
Train Loss: 2.02620  Test Loss: 2.01482  ||  Train Accuray: 0.26231  Test Accuray: 0.26591
 90%|█████████ | 90/100 [11:09:02<1:14:03, 444.32s/it]
Epoch: 91
Train Loss: 2.02682  Test Loss: 2.01742  ||  Train Accuray: 0.26218  Test Accuray: 0.26617
 91%|█████████ | 91/100 [11:16:26<1:06:38, 444.27s/it]
Epoch: 92
Train Loss: 2.02636  Test Loss: 2.01796  ||  Train Accuray: 0.25985  Test Accuray: 0.27002
 92%|█████████▏| 92/100 [11:23:51<59:14, 444.33s/it]  
Epoch: 93
Train Loss: 2.02647  Test Loss: 2.02412  ||  Train Accuray: 0.26188  Test Accuray: 0.25675
 93%|█████████▎| 93/100 [11:31:15<51:50, 444.34s/it]
Epoch: 94
Train Loss: 2.02702  Test Loss: 2.01448  ||  Train Accuray: 0.26278  Test Accuray: 0.27455
 94%|█████████▍| 94/100 [11:38:40<44:26, 444.35s/it]
Epoch: 95
Train Loss: 2.02676  Test Loss: 2.01662  ||  Train Accuray: 0.26372  Test Accuray: 0.27585
 95%|█████████▌| 95/100 [11:46:04<37:01, 444.40s/it]
Epoch: 96
Train Loss: 2.02747  Test Loss: 2.01892  ||  Train Accuray: 0.26295  Test Accuray: 0.26817
 96%|█████████▌| 96/100 [11:53:28<29:37, 444.37s/it]
Epoch: 97
Train Loss: 2.02761  Test Loss: 2.01747  ||  Train Accuray: 0.26300  Test Accuray: 0.27398
 97%|█████████▋| 97/100 [12:00:53<22:13, 444.42s/it]
Epoch: 98
Train Loss: 2.02771  Test Loss: 2.01937  ||  Train Accuray: 0.26075  Test Accuray: 0.27964
 98%|█████████▊| 98/100 [12:08:17<14:48, 444.37s/it]
Epoch: 99
Train Loss: 2.02834  Test Loss: 2.01776  ||  Train Accuray: 0.25929  Test Accuray: 0.26964
 99%|█████████▉| 99/100 [12:15:42<07:24, 444.38s/it]
Epoch: 100
Train Loss: 2.02854  Test Loss: 2.01669  ||  Train Accuray: 0.26102  Test Accuray: 0.26645
100%|██████████| 100/100 [12:23:06<00:00, 444.30s/it]100%|██████████| 100/100 [12:23:06<00:00, 445.86s/it]
wandb: - 0.027 MB of 0.027 MB uploadedwandb: \ 0.027 MB of 0.027 MB uploadedwandb: | 0.027 MB of 0.027 MB uploadedwandb: / 0.027 MB of 0.027 MB uploadedwandb: - 0.027 MB of 0.027 MB uploadedwandb: \ 0.027 MB of 0.027 MB uploadedwandb: | 0.027 MB of 0.027 MB uploadedwandb: / 0.031 MB of 0.036 MB uploaded (0.001 MB deduped)wandb: - 0.046 MB of 0.046 MB uploaded (0.001 MB deduped)wandb: \ 0.046 MB of 0.046 MB uploaded (0.001 MB deduped)wandb: | 0.046 MB of 0.046 MB uploaded (0.001 MB deduped)wandb: / 0.046 MB of 0.046 MB uploaded (0.001 MB deduped)wandb:                                                                                
wandb: W&B sync reduced upload amount by 2.4%
wandb: 
wandb: Run history:
wandb:     Test Accuracy ▁▂▅▅▅▅▆▇▇▇▇▇▆▇▇██▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇
wandb:         Test Loss █▅▃▃▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▂▁▂▂
wandb: Training Accuracy ▁▄▅▆▆▆▇▇▇▇██████████████████████████████
wandb:     Training Loss █▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:     Test Accuracy 0.26645
wandb:         Test Loss 2.01669
wandb: Training Accuracy 0.26102
wandb:     Training Loss 2.02854
wandb: 
wandb: 🚀 View run org_architecture_cifar10_Lr_3e-4_EMB_768_patch_16_depth_12 at: https://wandb.ai/maa_64/vit-small-data/runs/eugplg40
wandb: ⭐️ View project at: https://wandb.ai/maa_64/vit-small-data
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240928_184218-eugplg40/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.

Saving Model At: save_model/vit_model_org_architecture_cifar10_0.0003_64.pth
