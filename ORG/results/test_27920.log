Sat Aug 24 13:10:34 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:4E:00.0 Off |                    0 |
| N/A   25C    P0             54W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+


Experiment Name: org_architecture
Experiment Details: base vit architecture but Residual at only Multi head attention


Dataset Name: imagenet100
Seed: 64
Batch Size: 64
Number of Epochs: 100
Learning Rate: 3e-4
Input Channel: 3
Patch Size: 16
Embedding Size: 768
Input Image Size: 224
ViT Depth: 12
Number of Classes: 100
WandB Project: vit-small-data
WandB Run Name: org_architecture_imagenet100_Lr_3e-4_EMB_768_patch_16_depth_12
Output Directory: results


===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
‚îú‚îÄPatchEmbedding: 1-1                         [-1, 197, 768]            --
|    ‚îî‚îÄSequential: 2-1                        [-1, 196, 768]            --
|    |    ‚îî‚îÄConv2d: 3-1                       [-1, 768, 14, 14]         590,592
|    |    ‚îî‚îÄRearrange: 3-2                    [-1, 196, 768]            --
‚îú‚îÄTransformerEncoder: 1-2                     [-1, 197, 768]            --
|    ‚îî‚îÄTransformerEncoderBlock: 2-2           [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-3                     [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-4                   [-1, 197, 768]            4,723,968
|    ‚îî‚îÄTransformerEncoderBlock: 2-3           [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-5                     [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-6                   [-1, 197, 768]            4,723,968
|    ‚îî‚îÄTransformerEncoderBlock: 2-4           [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-7                     [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-8                   [-1, 197, 768]            4,723,968
|    ‚îî‚îÄTransformerEncoderBlock: 2-5           [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-9                     [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-10                  [-1, 197, 768]            4,723,968
|    ‚îî‚îÄTransformerEncoderBlock: 2-6           [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-11                    [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-12                  [-1, 197, 768]            4,723,968
|    ‚îî‚îÄTransformerEncoderBlock: 2-7           [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-13                    [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-14                  [-1, 197, 768]            4,723,968
|    ‚îî‚îÄTransformerEncoderBlock: 2-8           [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-15                    [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-16                  [-1, 197, 768]            4,723,968
|    ‚îî‚îÄTransformerEncoderBlock: 2-9           [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-17                    [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-18                  [-1, 197, 768]            4,723,968
|    ‚îî‚îÄTransformerEncoderBlock: 2-10          [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-19                    [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-20                  [-1, 197, 768]            4,723,968
|    ‚îî‚îÄTransformerEncoderBlock: 2-11          [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-21                    [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-22                  [-1, 197, 768]            4,723,968
|    ‚îî‚îÄTransformerEncoderBlock: 2-12          [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-23                    [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-24                  [-1, 197, 768]            4,723,968
|    ‚îî‚îÄTransformerEncoderBlock: 2-13          [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-25                    [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-26                  [-1, 197, 768]            4,723,968
‚îú‚îÄClassificationHead: 1-3                     [-1, 100]                 --
|    ‚îî‚îÄReduce: 2-14                           [-1, 768]                 --
|    ‚îî‚îÄLayerNorm: 2-15                        [-1, 768]                 1,536
|    ‚îî‚îÄLinear: 2-16                           [-1, 100]                 76,900
===============================================================================================
Total params: 85,723,492
Trainable params: 85,723,492
Non-trainable params: 0
Total mult-adds (M): 456.75
===============================================================================================
Input size (MB): 0.57
Forward/backward pass size (MB): 15.01
Params size (MB): 327.01
Estimated Total Size (MB): 342.59
===============================================================================================

 ===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
‚îú‚îÄPatchEmbedding: 1-1                         [-1, 197, 768]            --
|    ‚îî‚îÄSequential: 2-1                        [-1, 196, 768]            --
|    |    ‚îî‚îÄConv2d: 3-1                       [-1, 768, 14, 14]         590,592
|    |    ‚îî‚îÄRearrange: 3-2                    [-1, 196, 768]            --
‚îú‚îÄTransformerEncoder: 1-2                     [-1, 197, 768]            --
|    ‚îî‚îÄTransformerEncoderBlock: 2-2           [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-3                     [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-4                   [-1, 197, 768]            4,723,968
|    ‚îî‚îÄTransformerEncoderBlock: 2-3           [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-5                     [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-6                   [-1, 197, 768]            4,723,968
|    ‚îî‚îÄTransformerEncoderBlock: 2-4           [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-7                     [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-8                   [-1, 197, 768]            4,723,968
|    ‚îî‚îÄTransformerEncoderBlock: 2-5           [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-9                     [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-10                  [-1, 197, 768]            4,723,968
|    ‚îî‚îÄTransformerEncoderBlock: 2-6           [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-11                    [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-12                  [-1, 197, 768]            4,723,968
|    ‚îî‚îÄTransformerEncoderBlock: 2-7           [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-13                    [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-14                  [-1, 197, 768]            4,723,968
|    ‚îî‚îÄTransformerEncoderBlock: 2-8           [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-15                    [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-16                  [-1, 197, 768]            4,723,968
|    ‚îî‚îÄTransformerEncoderBlock: 2-9           [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-17                    [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-18                  [-1, 197, 768]            4,723,968
|    ‚îî‚îÄTransformerEncoderBlock: 2-10          [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-19                    [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-20                  [-1, 197, 768]            4,723,968
|    ‚îî‚îÄTransformerEncoderBlock: 2-11          [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-21                    [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-22                  [-1, 197, 768]            4,723,968
|    ‚îî‚îÄTransformerEncoderBlock: 2-12          [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-23                    [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-24                  [-1, 197, 768]            4,723,968
|    ‚îî‚îÄTransformerEncoderBlock: 2-13          [-1, 197, 768]            --
|    |    ‚îî‚îÄResidual: 3-25                    [-1, 197, 768]            2,363,904
|    |    ‚îî‚îÄSequential: 3-26                  [-1, 197, 768]            4,723,968
‚îú‚îÄClassificationHead: 1-3                     [-1, 100]                 --
|    ‚îî‚îÄReduce: 2-14                           [-1, 768]                 --
|    ‚îî‚îÄLayerNorm: 2-15                        [-1, 768]                 1,536
|    ‚îî‚îÄLinear: 2-16                           [-1, 100]                 76,900
===============================================================================================
Total params: 85,723,492
Trainable params: 85,723,492
Non-trainable params: 0
Total mult-adds (M): 456.75
===============================================================================================
Input size (MB): 0.57
Forward/backward pass size (MB): 15.01
Params size (MB): 327.01
Estimated Total Size (MB): 342.59
=============================================================================================== 

with ImageNet 100


EXP org_architecture: Original VIT on imagenet100 with depth 12 and LEARNIGN_RATE 0.0003



wandb: Currently logged in as: jashpatel8561 (maa_64). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.5
wandb: Run data is saved locally in /scratch/data/m22cs061/VIT_for_smallDB/ORG/wandb/run-20240824_131047-ddx5ahkg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run org_architecture_imagenet100_Lr_3e-4_EMB_768_patch_16_depth_12
wandb: ‚≠êÔ∏è View project at https://wandb.ai/maa_64/vit-small-data
wandb: üöÄ View run at https://wandb.ai/maa_64/vit-small-data/runs/ddx5ahkg
  0%|          | 0/100 [00:00<?, ?it/s]
Epoch: 1
Train Loss: 4.61235  Test Loss: 4.58793  ||  Train Accuray: 0.01056  Test Accuray: 0.00701
  1%|          | 1/100 [46:11<76:12:48, 2771.40s/it]
Epoch: 2
Train Loss: 4.48095  Test Loss: 4.37544  ||  Train Accuray: 0.02376  Test Accuray: 0.00563
  2%|‚ñè         | 2/100 [1:31:24<74:31:01, 2737.36s/it]
Epoch: 3
Train Loss: 4.35009  Test Loss: 4.33988  ||  Train Accuray: 0.03299  Test Accuray: 0.00510
  3%|‚ñé         | 3/100 [2:16:41<73:29:47, 2727.71s/it]
Epoch: 4
Train Loss: 4.27050  Test Loss: 4.25069  ||  Train Accuray: 0.04043  Test Accuray: 0.00506
  4%|‚ñç         | 4/100 [3:02:28<72:56:29, 2735.31s/it]
Epoch: 5
Train Loss: 4.16261  Test Loss: 4.17179  ||  Train Accuray: 0.04982  Test Accuray: 0.00568
  5%|‚ñå         | 5/100 [3:48:09<72:14:23, 2737.51s/it]
Epoch: 6
Train Loss: 4.07748  Test Loss: 4.12314  ||  Train Accuray: 0.05805  Test Accuray: 0.00676
  6%|‚ñå         | 6/100 [4:33:38<71:24:03, 2734.51s/it]
Epoch: 7
Train Loss: 4.00579  Test Loss: 4.05427  ||  Train Accuray: 0.06496  Test Accuray: 0.00775
  7%|‚ñã         | 7/100 [5:19:18<70:41:36, 2736.52s/it]