Sun Aug 11 13:58:59 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 555.42.02              Driver Version: 555.42.02      CUDA Version: 12.5     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:B7:00.0 Off |                    0 |
| N/A   48C    P0             58W /  400W |       1MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+


Experiment Name: org_architecture
Experiment Details: base vit architecture but Residual at only Multi head attention


Dataset Name: stl10
Seed: 64
Batch Size: 64
Number of Epochs: 100
Learning Rate: 3e-4
Input Channel: 3
Patch Size: 16
Embedding Size: 768
Input Image Size: 224
ViT Depth: 12
Number of Classes: 10
WandB Project: vit-small-data
WandB Run Name: org_architecture_stl10_Lr_3e-4_EMB_768_patch_16_depth_12
Output Directory: results


===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
├─PatchEmbedding: 1-1                         [-1, 197, 768]            --
|    └─Sequential: 2-1                        [-1, 196, 768]            --
|    |    └─Conv2d: 3-1                       [-1, 768, 14, 14]         590,592
|    |    └─Rearrange: 3-2                    [-1, 196, 768]            --
├─TransformerEncoder: 1-2                     [-1, 197, 768]            --
|    └─TransformerEncoderBlock: 2-2           [-1, 197, 768]            --
|    |    └─Residual: 3-3                     [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-4                   [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-3           [-1, 197, 768]            --
|    |    └─Residual: 3-5                     [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-6                   [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-4           [-1, 197, 768]            --
|    |    └─Residual: 3-7                     [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-8                   [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-5           [-1, 197, 768]            --
|    |    └─Residual: 3-9                     [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-10                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-6           [-1, 197, 768]            --
|    |    └─Residual: 3-11                    [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-12                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-7           [-1, 197, 768]            --
|    |    └─Residual: 3-13                    [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-14                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-8           [-1, 197, 768]            --
|    |    └─Residual: 3-15                    [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-16                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-9           [-1, 197, 768]            --
|    |    └─Residual: 3-17                    [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-18                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-10          [-1, 197, 768]            --
|    |    └─Residual: 3-19                    [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-20                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-11          [-1, 197, 768]            --
|    |    └─Residual: 3-21                    [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-22                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-12          [-1, 197, 768]            --
|    |    └─Residual: 3-23                    [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-24                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-13          [-1, 197, 768]            --
|    |    └─Residual: 3-25                    [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-26                  [-1, 197, 768]            4,723,968
├─ClassificationHead: 1-3                     [-1, 10]                  --
|    └─Reduce: 2-14                           [-1, 768]                 --
|    └─LayerNorm: 2-15                        [-1, 768]                 1,536
|    └─Linear: 2-16                           [-1, 10]                  7,690
===============================================================================================
Total params: 85,654,282
Trainable params: 85,654,282
Non-trainable params: 0
Total mult-adds (M): 456.61
===============================================================================================
Input size (MB): 0.57
Forward/backward pass size (MB): 15.01
Params size (MB): 326.75
Estimated Total Size (MB): 342.33
===============================================================================================

 ===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
├─PatchEmbedding: 1-1                         [-1, 197, 768]            --
|    └─Sequential: 2-1                        [-1, 196, 768]            --
|    |    └─Conv2d: 3-1                       [-1, 768, 14, 14]         590,592
|    |    └─Rearrange: 3-2                    [-1, 196, 768]            --
├─TransformerEncoder: 1-2                     [-1, 197, 768]            --
|    └─TransformerEncoderBlock: 2-2           [-1, 197, 768]            --
|    |    └─Residual: 3-3                     [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-4                   [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-3           [-1, 197, 768]            --
|    |    └─Residual: 3-5                     [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-6                   [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-4           [-1, 197, 768]            --
|    |    └─Residual: 3-7                     [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-8                   [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-5           [-1, 197, 768]            --
|    |    └─Residual: 3-9                     [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-10                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-6           [-1, 197, 768]            --
|    |    └─Residual: 3-11                    [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-12                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-7           [-1, 197, 768]            --
|    |    └─Residual: 3-13                    [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-14                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-8           [-1, 197, 768]            --
|    |    └─Residual: 3-15                    [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-16                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-9           [-1, 197, 768]            --
|    |    └─Residual: 3-17                    [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-18                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-10          [-1, 197, 768]            --
|    |    └─Residual: 3-19                    [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-20                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-11          [-1, 197, 768]            --
|    |    └─Residual: 3-21                    [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-22                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-12          [-1, 197, 768]            --
|    |    └─Residual: 3-23                    [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-24                  [-1, 197, 768]            4,723,968
|    └─TransformerEncoderBlock: 2-13          [-1, 197, 768]            --
|    |    └─Residual: 3-25                    [-1, 197, 768]            2,363,904
|    |    └─Sequential: 3-26                  [-1, 197, 768]            4,723,968
├─ClassificationHead: 1-3                     [-1, 10]                  --
|    └─Reduce: 2-14                           [-1, 768]                 --
|    └─LayerNorm: 2-15                        [-1, 768]                 1,536
|    └─Linear: 2-16                           [-1, 10]                  7,690
===============================================================================================
Total params: 85,654,282
Trainable params: 85,654,282
Non-trainable params: 0
Total mult-adds (M): 456.61
===============================================================================================
Input size (MB): 0.57
Forward/backward pass size (MB): 15.01
Params size (MB): 326.75
Estimated Total Size (MB): 342.33
=============================================================================================== 

with STL10
Files already downloaded and verified
Files already downloaded and verified


EXP org_architecture: Original VIT on stl10 with depth 12 and LEARNIGN_RATE 0.0003



wandb: Currently logged in as: jashpatel8561 (maa_64). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.17.6 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.5
wandb: Run data is saved locally in /scratch/data/m22cs061/VIT_for_smallDB/ORG/wandb/run-20240811_135933-sd1avewa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run org_architecture_stl10_Lr_3e-4_EMB_768_patch_16_depth_12
wandb: ⭐️ View project at https://wandb.ai/maa_64/vit-small-data
wandb: 🚀 View run at https://wandb.ai/maa_64/vit-small-data/runs/sd1avewa
  0%|          | 0/100 [00:00<?, ?it/s]
Epoch: 1
Train Loss: 2.31971  Test Loss: 2.30677  ||  Train Accuray: 0.10063  Test Accuray: 0.10000
  1%|          | 1/100 [01:12<1:59:03, 72.16s/it]
Epoch: 2
Train Loss: 2.31086  Test Loss: 2.30288  ||  Train Accuray: 0.10299  Test Accuray: 0.10000
  2%|▏         | 2/100 [02:22<1:56:33, 71.37s/it]
Epoch: 3
Train Loss: 2.30625  Test Loss: 2.29195  ||  Train Accuray: 0.10891  Test Accuray: 0.13214
  3%|▎         | 3/100 [03:33<1:54:27, 70.80s/it]
Epoch: 4
Train Loss: 2.30357  Test Loss: 2.27025  ||  Train Accuray: 0.12094  Test Accuray: 0.10632
  4%|▍         | 4/100 [04:43<1:52:48, 70.50s/it]
Epoch: 5
Train Loss: 2.29083  Test Loss: 2.26111  ||  Train Accuray: 0.12857  Test Accuray: 0.14607
  5%|▌         | 5/100 [05:53<1:51:25, 70.38s/it]
Epoch: 6
Train Loss: 2.27419  Test Loss: 2.29358  ||  Train Accuray: 0.14264  Test Accuray: 0.12013
  6%|▌         | 6/100 [07:03<1:50:09, 70.31s/it]
Epoch: 7
Train Loss: 2.25565  Test Loss: 2.19015  ||  Train Accuray: 0.15684  Test Accuray: 0.18572
  7%|▋         | 7/100 [08:13<1:48:39, 70.10s/it]
Epoch: 8
Train Loss: 2.23489  Test Loss: 2.28627  ||  Train Accuray: 0.16543  Test Accuray: 0.14987
  8%|▊         | 8/100 [09:22<1:47:19, 69.99s/it]
Epoch: 9
Train Loss: 2.21036  Test Loss: 2.26935  ||  Train Accuray: 0.17573  Test Accuray: 0.16851
  9%|▉         | 9/100 [10:32<1:46:11, 70.02s/it]
Epoch: 10
Train Loss: 2.19495  Test Loss: 2.34776  ||  Train Accuray: 0.17843  Test Accuray: 0.15464
 10%|█         | 10/100 [11:42<1:44:55, 69.95s/it]
Epoch: 11
Train Loss: 2.18167  Test Loss: 2.20317  ||  Train Accuray: 0.18484  Test Accuray: 0.19341
 11%|█         | 11/100 [12:52<1:43:40, 69.89s/it]
Epoch: 12
Train Loss: 2.16220  Test Loss: 2.14680  ||  Train Accuray: 0.19851  Test Accuray: 0.18640
 12%|█▏        | 12/100 [14:02<1:42:27, 69.86s/it]
Epoch: 13
Train Loss: 2.14155  Test Loss: 2.24747  ||  Train Accuray: 0.19970  Test Accuray: 0.18873
 13%|█▎        | 13/100 [15:12<1:41:19, 69.88s/it]
Epoch: 14
Train Loss: 2.12838  Test Loss: 2.13429  ||  Train Accuray: 0.20209  Test Accuray: 0.19840
 14%|█▍        | 14/100 [16:22<1:40:07, 69.86s/it]
Epoch: 15
Train Loss: 2.11069  Test Loss: 2.06139  ||  Train Accuray: 0.20902  Test Accuray: 0.23349
 15%|█▌        | 15/100 [17:31<1:38:54, 69.82s/it]
Epoch: 16
Train Loss: 2.07638  Test Loss: 2.02341  ||  Train Accuray: 0.22410  Test Accuray: 0.24952
 16%|█▌        | 16/100 [18:41<1:37:40, 69.76s/it]
Epoch: 17
Train Loss: 2.06958  Test Loss: 2.05524  ||  Train Accuray: 0.22948  Test Accuray: 0.23857
 17%|█▋        | 17/100 [19:51<1:36:29, 69.76s/it]
Epoch: 18
Train Loss: 2.04332  Test Loss: 1.96853  ||  Train Accuray: 0.24298  Test Accuray: 0.25797
 18%|█▊        | 18/100 [21:00<1:35:10, 69.63s/it]
Epoch: 19
Train Loss: 2.01822  Test Loss: 2.03755  ||  Train Accuray: 0.25145  Test Accuray: 0.25139
 19%|█▉        | 19/100 [22:10<1:33:59, 69.63s/it]
Epoch: 20
Train Loss: 2.00287  Test Loss: 2.01468  ||  Train Accuray: 0.25215  Test Accuray: 0.26001
 20%|██        | 20/100 [23:19<1:32:52, 69.66s/it]
Epoch: 21
Train Loss: 1.99045  Test Loss: 1.94095  ||  Train Accuray: 0.25666  Test Accuray: 0.27123
 21%|██        | 21/100 [24:29<1:31:40, 69.62s/it]
Epoch: 22
Train Loss: 1.96775  Test Loss: 1.91498  ||  Train Accuray: 0.25923  Test Accuray: 0.25783
 22%|██▏       | 22/100 [25:38<1:30:26, 69.58s/it]
Epoch: 23
Train Loss: 1.95510  Test Loss: 1.97043  ||  Train Accuray: 0.25760  Test Accuray: 0.25527
 23%|██▎       | 23/100 [26:48<1:29:25, 69.68s/it]
Epoch: 24
Train Loss: 1.93577  Test Loss: 1.92625  ||  Train Accuray: 0.26769  Test Accuray: 0.24627
 24%|██▍       | 24/100 [27:58<1:28:16, 69.69s/it]
Epoch: 25
Train Loss: 1.92729  Test Loss: 1.96384  ||  Train Accuray: 0.27078  Test Accuray: 0.24013
 25%|██▌       | 25/100 [29:08<1:27:03, 69.65s/it]
Epoch: 26
Train Loss: 1.92231  Test Loss: 1.89804  ||  Train Accuray: 0.26737  Test Accuray: 0.25592
 26%|██▌       | 26/100 [30:17<1:25:54, 69.65s/it]
Epoch: 27
Train Loss: 1.89483  Test Loss: 1.90942  ||  Train Accuray: 0.27644  Test Accuray: 0.24810
 27%|██▋       | 27/100 [31:27<1:24:44, 69.66s/it]
Epoch: 28
Train Loss: 1.91010  Test Loss: 1.93151  ||  Train Accuray: 0.26421  Test Accuray: 0.25476
 28%|██▊       | 28/100 [32:36<1:23:26, 69.53s/it]
Epoch: 29
Train Loss: 1.88327  Test Loss: 1.90538  ||  Train Accuray: 0.27500  Test Accuray: 0.25931
 29%|██▉       | 29/100 [33:46<1:22:17, 69.54s/it]
Epoch: 30
Train Loss: 1.88550  Test Loss: 1.90200  ||  Train Accuray: 0.27564  Test Accuray: 0.24850
 30%|███       | 30/100 [34:55<1:21:08, 69.55s/it]
Epoch: 31
Train Loss: 1.87543  Test Loss: 1.96735  ||  Train Accuray: 0.28622  Test Accuray: 0.25237
 31%|███       | 31/100 [36:05<1:20:01, 69.58s/it]
Epoch: 32
Train Loss: 1.87410  Test Loss: 1.92398  ||  Train Accuray: 0.27817  Test Accuray: 0.25654
 32%|███▏      | 32/100 [37:14<1:18:50, 69.56s/it]
Epoch: 33
Train Loss: 1.86403  Test Loss: 1.91752  ||  Train Accuray: 0.29253  Test Accuray: 0.25103
 33%|███▎      | 33/100 [38:24<1:17:37, 69.51s/it]
Epoch: 34
Train Loss: 1.86021  Test Loss: 2.01657  ||  Train Accuray: 0.28423  Test Accuray: 0.25819
 34%|███▍      | 34/100 [39:33<1:16:26, 69.50s/it]
Epoch: 35
Train Loss: 1.84986  Test Loss: 1.92454  ||  Train Accuray: 0.29666  Test Accuray: 0.25688
 35%|███▌      | 35/100 [40:43<1:15:19, 69.53s/it]
Epoch: 36
Train Loss: 1.85557  Test Loss: 1.92312  ||  Train Accuray: 0.29061  Test Accuray: 0.27323
 36%|███▌      | 36/100 [41:53<1:14:18, 69.66s/it]
Epoch: 37
Train Loss: 1.83859  Test Loss: 1.95274  ||  Train Accuray: 0.29787  Test Accuray: 0.23494
 37%|███▋      | 37/100 [43:03<1:13:10, 69.69s/it]
Epoch: 38
Train Loss: 1.84130  Test Loss: 2.03042  ||  Train Accuray: 0.29644  Test Accuray: 0.22952
 38%|███▊      | 38/100 [44:13<1:12:09, 69.83s/it]
Epoch: 39
Train Loss: 1.85018  Test Loss: 2.08057  ||  Train Accuray: 0.28774  Test Accuray: 0.23133
 39%|███▉      | 39/100 [45:23<1:10:57, 69.79s/it]
Epoch: 40
Train Loss: 1.82999  Test Loss: 1.98334  ||  Train Accuray: 0.29615  Test Accuray: 0.26259
 40%|████      | 40/100 [46:32<1:09:42, 69.72s/it]
Epoch: 41
Train Loss: 1.83992  Test Loss: 2.08499  ||  Train Accuray: 0.30104  Test Accuray: 0.22032
 41%|████      | 41/100 [47:42<1:08:30, 69.66s/it]
Epoch: 42
Train Loss: 1.82856  Test Loss: 1.97592  ||  Train Accuray: 0.30069  Test Accuray: 0.24797
 42%|████▏     | 42/100 [48:51<1:07:16, 69.60s/it]
Epoch: 43
Train Loss: 1.82533  Test Loss: 1.94884  ||  Train Accuray: 0.30946  Test Accuray: 0.23716
 43%|████▎     | 43/100 [50:01<1:06:05, 69.57s/it]
Epoch: 44
Train Loss: 1.81376  Test Loss: 2.09279  ||  Train Accuray: 0.30466  Test Accuray: 0.21981
 44%|████▍     | 44/100 [51:10<1:04:54, 69.54s/it]
Epoch: 45
Train Loss: 1.81495  Test Loss: 2.09999  ||  Train Accuray: 0.30400  Test Accuray: 0.20877
 45%|████▌     | 45/100 [52:20<1:03:44, 69.53s/it]
Epoch: 46
Train Loss: 1.81517  Test Loss: 1.89165  ||  Train Accuray: 0.30958  Test Accuray: 0.25016
 46%|████▌     | 46/100 [53:29<1:02:32, 69.50s/it]
Epoch: 47
Train Loss: 1.80683  Test Loss: 2.02680  ||  Train Accuray: 0.31154  Test Accuray: 0.23857
 47%|████▋     | 47/100 [54:39<1:01:24, 69.52s/it]
Epoch: 48
Train Loss: 1.80678  Test Loss: 1.91739  ||  Train Accuray: 0.31313  Test Accuray: 0.25719
 48%|████▊     | 48/100 [55:48<1:00:16, 69.55s/it]
Epoch: 49
Train Loss: 1.79968  Test Loss: 2.16301  ||  Train Accuray: 0.29786  Test Accuray: 0.21882
 49%|████▉     | 49/100 [56:58<59:08, 69.58s/it]  
Epoch: 50
Train Loss: 1.80078  Test Loss: 2.08638  ||  Train Accuray: 0.31049  Test Accuray: 0.21985
 50%|█████     | 50/100 [58:08<58:05, 69.72s/it]
Epoch: 51
Train Loss: 1.79753  Test Loss: 2.00734  ||  Train Accuray: 0.31752  Test Accuray: 0.25424
 51%|█████     | 51/100 [59:17<56:54, 69.68s/it]
Epoch: 52
Train Loss: 1.79580  Test Loss: 2.32996  ||  Train Accuray: 0.31208  Test Accuray: 0.19577
 52%|█████▏    | 52/100 [1:00:27<55:50, 69.80s/it]
Epoch: 53
Train Loss: 1.79415  Test Loss: 1.99980  ||  Train Accuray: 0.32088  Test Accuray: 0.25761
 53%|█████▎    | 53/100 [1:01:38<54:46, 69.92s/it]
Epoch: 54
Train Loss: 1.79612  Test Loss: 2.13759  ||  Train Accuray: 0.31925  Test Accuray: 0.21755
 54%|█████▍    | 54/100 [1:02:47<53:30, 69.79s/it]
Epoch: 55
Train Loss: 1.79253  Test Loss: 2.13873  ||  Train Accuray: 0.31497  Test Accuray: 0.23127
 55%|█████▌    | 55/100 [1:03:57<52:15, 69.69s/it]
Epoch: 56
Train Loss: 1.78468  Test Loss: 2.29214  ||  Train Accuray: 0.32253  Test Accuray: 0.22536
 56%|█████▌    | 56/100 [1:05:07<51:09, 69.77s/it]
Epoch: 57
Train Loss: 1.77989  Test Loss: 2.01156  ||  Train Accuray: 0.32463  Test Accuray: 0.23574
 57%|█████▋    | 57/100 [1:06:17<50:03, 69.85s/it]
Epoch: 58
Train Loss: 1.78142  Test Loss: 2.04048  ||  Train Accuray: 0.31544  Test Accuray: 0.25909
 58%|█████▊    | 58/100 [1:07:26<48:50, 69.78s/it]
Epoch: 59
Train Loss: 1.77095  Test Loss: 1.95001  ||  Train Accuray: 0.31723  Test Accuray: 0.26132
 59%|█████▉    | 59/100 [1:08:36<47:36, 69.66s/it]
Epoch: 60
Train Loss: 1.77583  Test Loss: 2.12997  ||  Train Accuray: 0.32230  Test Accuray: 0.22107
 60%|██████    | 60/100 [1:09:45<46:23, 69.60s/it]
Epoch: 61
Train Loss: 1.76994  Test Loss: 2.27789  ||  Train Accuray: 0.33299  Test Accuray: 0.20682
 61%|██████    | 61/100 [1:10:54<45:11, 69.53s/it]
Epoch: 62
Train Loss: 1.76759  Test Loss: 2.17944  ||  Train Accuray: 0.32459  Test Accuray: 0.21829
 62%|██████▏   | 62/100 [1:12:04<44:00, 69.50s/it]slurmstepd: error: *** JOB 24589 ON gpu2 CANCELLED AT 2024-08-11T15:11:56 ***
