exp_name: "org_architecture"
details: "base vit architecture Residual only at Multi head attention and norm layer only at Feed Forwoard Layer (NL,FF,DropL)"
dataset_name: "cifar10"
seed: 64
batch_size: 64
num_epoch: 100
learning_rate: 3e-4
input_channel: 3
patch_size: 16
# embedding_size: 768
input_image_size: 224
vit_depth: 12
num_class: 10
wandb_project: "vit-small-data"
output_dir: "results"